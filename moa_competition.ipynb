{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:04.809247Z",
     "iopub.status.busy": "2020-10-25T13:15:04.808323Z",
     "iopub.status.idle": "2020-10-25T13:15:04.815113Z",
     "shell.execute_reply": "2020-10-25T13:15:04.814466Z"
    },
    "papermill": {
     "duration": 0.03088,
     "end_time": "2020-10-25T13:15:04.815221",
     "exception": false,
     "start_time": "2020-10-25T13:15:04.784341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lish-moa/test_features.csv\n",
      "/kaggle/input/lish-moa/sample_submission.csv\n",
      "/kaggle/input/lish-moa/train_features.csv\n",
      "/kaggle/input/lish-moa/train_targets_scored.csv\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\n",
      "/kaggle/input/moa-comp/stratified_train_kfolds.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:04.855857Z",
     "iopub.status.busy": "2020-10-25T13:15:04.855134Z",
     "iopub.status.idle": "2020-10-25T13:15:13.436307Z",
     "shell.execute_reply": "2020-10-25T13:15:13.435183Z"
    },
    "papermill": {
     "duration": 8.603936,
     "end_time": "2020-10-25T13:15:13.436445",
     "exception": false,
     "start_time": "2020-10-25T13:15:04.832509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\n",
    "train_target_scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n",
    "train_target_nonscored = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/lish-moa/test_features.csv') \n",
    "submission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:13.477482Z",
     "iopub.status.busy": "2020-10-25T13:15:13.476469Z",
     "iopub.status.idle": "2020-10-25T13:15:13.481009Z",
     "shell.execute_reply": "2020-10-25T13:15:13.480549Z"
    },
    "papermill": {
     "duration": 0.026971,
     "end_time": "2020-10-25T13:15:13.481119",
     "exception": false,
     "start_time": "2020-10-25T13:15:13.454148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 876)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:13.523117Z",
     "iopub.status.busy": "2020-10-25T13:15:13.522512Z",
     "iopub.status.idle": "2020-10-25T13:15:13.556674Z",
     "shell.execute_reply": "2020-10-25T13:15:13.555996Z"
    },
    "papermill": {
     "duration": 0.058483,
     "end_time": "2020-10-25T13:15:13.556797",
     "exception": false,
     "start_time": "2020-10-25T13:15:13.498314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_000644bb2  trt_cp       24      D1  1.0620  0.5577 -0.2479 -0.6208   \n",
       "1  id_000779bfc  trt_cp       72      D1  0.0743  0.4087  0.2991  0.0604   \n",
       "2  id_000a6266a  trt_cp       48      D1  0.6280  0.5817  1.5540 -0.0764   \n",
       "3  id_0015fd391  trt_cp       48      D1 -0.5138 -0.2491 -0.2656  0.5288   \n",
       "4  id_001626bd3  trt_cp       72      D2 -0.3254 -0.4009  0.9700  0.6919   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n",
       "1  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n",
       "2 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n",
       "3  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n",
       "4  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0 -0.3981  0.2139  0.3801  0.4176  \n",
       "1  0.1522  0.1241  0.6077  0.7371  \n",
       "2 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4  0.1094  0.2885 -0.3786  0.7125  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:13.608433Z",
     "iopub.status.busy": "2020-10-25T13:15:13.607534Z",
     "iopub.status.idle": "2020-10-25T13:15:13.617317Z",
     "shell.execute_reply": "2020-10-25T13:15:13.616834Z"
    },
    "papermill": {
     "duration": 0.039655,
     "end_time": "2020-10-25T13:15:13.617432",
     "exception": false,
     "start_time": "2020-10-25T13:15:13.577777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23814"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sig_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:13.662763Z",
     "iopub.status.busy": "2020-10-25T13:15:13.662031Z",
     "iopub.status.idle": "2020-10-25T13:15:13.670604Z",
     "shell.execute_reply": "2020-10-25T13:15:13.670124Z"
    },
    "papermill": {
     "duration": 0.032708,
     "end_time": "2020-10-25T13:15:13.670701",
     "exception": false,
     "start_time": "2020-10-25T13:15:13.637993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48    8250\n",
       "72    7792\n",
       "24    7772\n",
       "Name: cp_time, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.cp_time.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:13.718848Z",
     "iopub.status.busy": "2020-10-25T13:15:13.717915Z",
     "iopub.status.idle": "2020-10-25T13:15:13.724234Z",
     "shell.execute_reply": "2020-10-25T13:15:13.724804Z"
    },
    "papermill": {
     "duration": 0.035754,
     "end_time": "2020-10-25T13:15:13.724915",
     "exception": false,
     "start_time": "2020-10-25T13:15:13.689161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D1    12147\n",
       "D2    11667\n",
       "Name: cp_dose, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.cp_dose.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:13.780492Z",
     "iopub.status.busy": "2020-10-25T13:15:13.779793Z",
     "iopub.status.idle": "2020-10-25T13:15:13.783222Z",
     "shell.execute_reply": "2020-10-25T13:15:13.783741Z"
    },
    "papermill": {
     "duration": 0.037634,
     "end_time": "2020-10-25T13:15:13.783848",
     "exception": false,
     "start_time": "2020-10-25T13:15:13.746214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trt_cp         21948\n",
       "ctl_vehicle     1866\n",
       "Name: cp_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.cp_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:13.827959Z",
     "iopub.status.busy": "2020-10-25T13:15:13.827145Z",
     "iopub.status.idle": "2020-10-25T13:15:13.831608Z",
     "shell.execute_reply": "2020-10-25T13:15:13.832068Z"
    },
    "papermill": {
     "duration": 0.028534,
     "end_time": "2020-10-25T13:15:13.832185",
     "exception": false,
     "start_time": "2020-10-25T13:15:13.803651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 207)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_scored.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:13.893422Z",
     "iopub.status.busy": "2020-10-25T13:15:13.892769Z",
     "iopub.status.idle": "2020-10-25T13:15:13.898996Z",
     "shell.execute_reply": "2020-10-25T13:15:13.898474Z"
    },
    "papermill": {
     "duration": 0.045834,
     "end_time": "2020-10-25T13:15:13.899084",
     "exception": false,
     "start_time": "2020-10-25T13:15:13.853250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_000644bb2                            0                       0   \n",
       "1  id_000779bfc                            0                       0   \n",
       "2  id_000a6266a                            0                       0   \n",
       "3  id_0015fd391                            0                       0   \n",
       "4  id_001626bd3                            0                       0   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0               0                               0   \n",
       "1               0                               0   \n",
       "2               0                               0   \n",
       "3               0                               0   \n",
       "4               0                               0   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                  0                               0   \n",
       "1                                  0                               0   \n",
       "2                                  0                               0   \n",
       "3                                  0                               0   \n",
       "4                                  0                               0   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                           0                              0   \n",
       "1                           0                              0   \n",
       "2                           0                              0   \n",
       "3                           0                              0   \n",
       "4                           0                              0   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                           0  ...                                      0   \n",
       "1                           0  ...                                      0   \n",
       "2                           0  ...                                      0   \n",
       "3                           0  ...                                      0   \n",
       "4                           0  ...                                      0   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0             0                0                  0   \n",
       "1             0                0                  0   \n",
       "2             0                0                  0   \n",
       "3             0                0                  0   \n",
       "4             0                0                  0   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                0          0                           0              0  \n",
       "1                0          0                           0              0  \n",
       "2                0          0                           0              0  \n",
       "3                0          0                           0              0  \n",
       "4                0          0                           0              0  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_scored.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:13.948835Z",
     "iopub.status.busy": "2020-10-25T13:15:13.948148Z",
     "iopub.status.idle": "2020-10-25T13:15:14.105882Z",
     "shell.execute_reply": "2020-10-25T13:15:14.106353Z"
    },
    "papermill": {
     "duration": 0.18502,
     "end_time": "2020-10-25T13:15:14.106493",
     "exception": false,
     "start_time": "2020-10-25T13:15:13.921473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "atp-sensitive_potassium_channel_antagonist      1\n",
       "erbb2_inhibitor                                 1\n",
       "diuretic                                        6\n",
       "autotaxin_inhibitor                             6\n",
       "protein_phosphatase_inhibitor                   6\n",
       "                                             ... \n",
       "serotonin_receptor_antagonist                 404\n",
       "dopamine_receptor_antagonist                  424\n",
       "cyclooxygenase_inhibitor                      435\n",
       "proteasome_inhibitor                          726\n",
       "nfkb_inhibitor                                832\n",
       "Length: 206, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_scored.sum()[1:].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:14.161754Z",
     "iopub.status.busy": "2020-10-25T13:15:14.160931Z",
     "iopub.status.idle": "2020-10-25T13:15:15.247300Z",
     "shell.execute_reply": "2020-10-25T13:15:15.246189Z"
    },
    "papermill": {
     "duration": 1.118164,
     "end_time": "2020-10-25T13:15:15.247505",
     "exception": false,
     "start_time": "2020-10-25T13:15:14.129341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "cat_features = ['cp_type','cp_time','cp_dose']\n",
    "for feat in cat_features:\n",
    "    lbl = preprocessing.LabelEncoder() \n",
    "    lbl.fit(train_data[feat].astype(str).values)\n",
    "    test_data.loc[:,feat] = test_data[feat].map(lambda s: '<unknown>' if s not in lbl.classes_ else s)\n",
    "    lbl.classes_ = np.append(lbl.classes_, '<unknown>')\n",
    "    train_data.loc[:,feat] = lbl.transform(train_data[feat].astype(str).values)\n",
    "    test_data.loc[:,feat] = lbl.transform(test_data[feat].astype(str).values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:15.299672Z",
     "iopub.status.busy": "2020-10-25T13:15:15.298793Z",
     "iopub.status.idle": "2020-10-25T13:15:15.303477Z",
     "shell.execute_reply": "2020-10-25T13:15:15.304154Z"
    },
    "papermill": {
     "duration": 0.03283,
     "end_time": "2020-10-25T13:15:15.304301",
     "exception": false,
     "start_time": "2020-10-25T13:15:15.271471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cp_type', 'cp_time', 'cp_dose', 'g-0', 'g-1', 'g-2', 'g-3', 'g-4', 'g-5', 'g-6', 'g-7', 'g-8', 'g-9', 'g-10', 'g-11', 'g-12', 'g-13', 'g-14', 'g-15', 'g-16', 'g-17', 'g-18', 'g-19', 'g-20', 'g-21', 'g-22', 'g-23', 'g-24', 'g-25', 'g-26', 'g-27', 'g-28', 'g-29', 'g-30', 'g-31', 'g-32', 'g-33', 'g-34', 'g-35', 'g-36', 'g-37', 'g-38', 'g-39', 'g-40', 'g-41', 'g-42', 'g-43', 'g-44', 'g-45', 'g-46', 'g-47', 'g-48', 'g-49', 'g-50', 'g-51', 'g-52', 'g-53', 'g-54', 'g-55', 'g-56', 'g-57', 'g-58', 'g-59', 'g-60', 'g-61', 'g-62', 'g-63', 'g-64', 'g-65', 'g-66', 'g-67', 'g-68', 'g-69', 'g-70', 'g-71', 'g-72', 'g-73', 'g-74', 'g-75', 'g-76', 'g-77', 'g-78', 'g-79', 'g-80', 'g-81', 'g-82', 'g-83', 'g-84', 'g-85', 'g-86', 'g-87', 'g-88', 'g-89', 'g-90', 'g-91', 'g-92', 'g-93', 'g-94', 'g-95', 'g-96', 'g-97', 'g-98', 'g-99', 'g-100', 'g-101', 'g-102', 'g-103', 'g-104', 'g-105', 'g-106', 'g-107', 'g-108', 'g-109', 'g-110', 'g-111', 'g-112', 'g-113', 'g-114', 'g-115', 'g-116', 'g-117', 'g-118', 'g-119', 'g-120', 'g-121', 'g-122', 'g-123', 'g-124', 'g-125', 'g-126', 'g-127', 'g-128', 'g-129', 'g-130', 'g-131', 'g-132', 'g-133', 'g-134', 'g-135', 'g-136', 'g-137', 'g-138', 'g-139', 'g-140', 'g-141', 'g-142', 'g-143', 'g-144', 'g-145', 'g-146', 'g-147', 'g-148', 'g-149', 'g-150', 'g-151', 'g-152', 'g-153', 'g-154', 'g-155', 'g-156', 'g-157', 'g-158', 'g-159', 'g-160', 'g-161', 'g-162', 'g-163', 'g-164', 'g-165', 'g-166', 'g-167', 'g-168', 'g-169', 'g-170', 'g-171', 'g-172', 'g-173', 'g-174', 'g-175', 'g-176', 'g-177', 'g-178', 'g-179', 'g-180', 'g-181', 'g-182', 'g-183', 'g-184', 'g-185', 'g-186', 'g-187', 'g-188', 'g-189', 'g-190', 'g-191', 'g-192', 'g-193', 'g-194', 'g-195', 'g-196', 'g-197', 'g-198', 'g-199', 'g-200', 'g-201', 'g-202', 'g-203', 'g-204', 'g-205', 'g-206', 'g-207', 'g-208', 'g-209', 'g-210', 'g-211', 'g-212', 'g-213', 'g-214', 'g-215', 'g-216', 'g-217', 'g-218', 'g-219', 'g-220', 'g-221', 'g-222', 'g-223', 'g-224', 'g-225', 'g-226', 'g-227', 'g-228', 'g-229', 'g-230', 'g-231', 'g-232', 'g-233', 'g-234', 'g-235', 'g-236', 'g-237', 'g-238', 'g-239', 'g-240', 'g-241', 'g-242', 'g-243', 'g-244', 'g-245', 'g-246', 'g-247', 'g-248', 'g-249', 'g-250', 'g-251', 'g-252', 'g-253', 'g-254', 'g-255', 'g-256', 'g-257', 'g-258', 'g-259', 'g-260', 'g-261', 'g-262', 'g-263', 'g-264', 'g-265', 'g-266', 'g-267', 'g-268', 'g-269', 'g-270', 'g-271', 'g-272', 'g-273', 'g-274', 'g-275', 'g-276', 'g-277', 'g-278', 'g-279', 'g-280', 'g-281', 'g-282', 'g-283', 'g-284', 'g-285', 'g-286', 'g-287', 'g-288', 'g-289', 'g-290', 'g-291', 'g-292', 'g-293', 'g-294', 'g-295', 'g-296', 'g-297', 'g-298', 'g-299', 'g-300', 'g-301', 'g-302', 'g-303', 'g-304', 'g-305', 'g-306', 'g-307', 'g-308', 'g-309', 'g-310', 'g-311', 'g-312', 'g-313', 'g-314', 'g-315', 'g-316', 'g-317', 'g-318', 'g-319', 'g-320', 'g-321', 'g-322', 'g-323', 'g-324', 'g-325', 'g-326', 'g-327', 'g-328', 'g-329', 'g-330', 'g-331', 'g-332', 'g-333', 'g-334', 'g-335', 'g-336', 'g-337', 'g-338', 'g-339', 'g-340', 'g-341', 'g-342', 'g-343', 'g-344', 'g-345', 'g-346', 'g-347', 'g-348', 'g-349', 'g-350', 'g-351', 'g-352', 'g-353', 'g-354', 'g-355', 'g-356', 'g-357', 'g-358', 'g-359', 'g-360', 'g-361', 'g-362', 'g-363', 'g-364', 'g-365', 'g-366', 'g-367', 'g-368', 'g-369', 'g-370', 'g-371', 'g-372', 'g-373', 'g-374', 'g-375', 'g-376', 'g-377', 'g-378', 'g-379', 'g-380', 'g-381', 'g-382', 'g-383', 'g-384', 'g-385', 'g-386', 'g-387', 'g-388', 'g-389', 'g-390', 'g-391', 'g-392', 'g-393', 'g-394', 'g-395', 'g-396', 'g-397', 'g-398', 'g-399', 'g-400', 'g-401', 'g-402', 'g-403', 'g-404', 'g-405', 'g-406', 'g-407', 'g-408', 'g-409', 'g-410', 'g-411', 'g-412', 'g-413', 'g-414', 'g-415', 'g-416', 'g-417', 'g-418', 'g-419', 'g-420', 'g-421', 'g-422', 'g-423', 'g-424', 'g-425', 'g-426', 'g-427', 'g-428', 'g-429', 'g-430', 'g-431', 'g-432', 'g-433', 'g-434', 'g-435', 'g-436', 'g-437', 'g-438', 'g-439', 'g-440', 'g-441', 'g-442', 'g-443', 'g-444', 'g-445', 'g-446', 'g-447', 'g-448', 'g-449', 'g-450', 'g-451', 'g-452', 'g-453', 'g-454', 'g-455', 'g-456', 'g-457', 'g-458', 'g-459', 'g-460', 'g-461', 'g-462', 'g-463', 'g-464', 'g-465', 'g-466', 'g-467', 'g-468', 'g-469', 'g-470', 'g-471', 'g-472', 'g-473', 'g-474', 'g-475', 'g-476', 'g-477', 'g-478', 'g-479', 'g-480', 'g-481', 'g-482', 'g-483', 'g-484', 'g-485', 'g-486', 'g-487', 'g-488', 'g-489', 'g-490', 'g-491', 'g-492', 'g-493', 'g-494', 'g-495', 'g-496', 'g-497', 'g-498', 'g-499', 'g-500', 'g-501', 'g-502', 'g-503', 'g-504', 'g-505', 'g-506', 'g-507', 'g-508', 'g-509', 'g-510', 'g-511', 'g-512', 'g-513', 'g-514', 'g-515', 'g-516', 'g-517', 'g-518', 'g-519', 'g-520', 'g-521', 'g-522', 'g-523', 'g-524', 'g-525', 'g-526', 'g-527', 'g-528', 'g-529', 'g-530', 'g-531', 'g-532', 'g-533', 'g-534', 'g-535', 'g-536', 'g-537', 'g-538', 'g-539', 'g-540', 'g-541', 'g-542', 'g-543', 'g-544', 'g-545', 'g-546', 'g-547', 'g-548', 'g-549', 'g-550', 'g-551', 'g-552', 'g-553', 'g-554', 'g-555', 'g-556', 'g-557', 'g-558', 'g-559', 'g-560', 'g-561', 'g-562', 'g-563', 'g-564', 'g-565', 'g-566', 'g-567', 'g-568', 'g-569', 'g-570', 'g-571', 'g-572', 'g-573', 'g-574', 'g-575', 'g-576', 'g-577', 'g-578', 'g-579', 'g-580', 'g-581', 'g-582', 'g-583', 'g-584', 'g-585', 'g-586', 'g-587', 'g-588', 'g-589', 'g-590', 'g-591', 'g-592', 'g-593', 'g-594', 'g-595', 'g-596', 'g-597', 'g-598', 'g-599', 'g-600', 'g-601', 'g-602', 'g-603', 'g-604', 'g-605', 'g-606', 'g-607', 'g-608', 'g-609', 'g-610', 'g-611', 'g-612', 'g-613', 'g-614', 'g-615', 'g-616', 'g-617', 'g-618', 'g-619', 'g-620', 'g-621', 'g-622', 'g-623', 'g-624', 'g-625', 'g-626', 'g-627', 'g-628', 'g-629', 'g-630', 'g-631', 'g-632', 'g-633', 'g-634', 'g-635', 'g-636', 'g-637', 'g-638', 'g-639', 'g-640', 'g-641', 'g-642', 'g-643', 'g-644', 'g-645', 'g-646', 'g-647', 'g-648', 'g-649', 'g-650', 'g-651', 'g-652', 'g-653', 'g-654', 'g-655', 'g-656', 'g-657', 'g-658', 'g-659', 'g-660', 'g-661', 'g-662', 'g-663', 'g-664', 'g-665', 'g-666', 'g-667', 'g-668', 'g-669', 'g-670', 'g-671', 'g-672', 'g-673', 'g-674', 'g-675', 'g-676', 'g-677', 'g-678', 'g-679', 'g-680', 'g-681', 'g-682', 'g-683', 'g-684', 'g-685', 'g-686', 'g-687', 'g-688', 'g-689', 'g-690', 'g-691', 'g-692', 'g-693', 'g-694', 'g-695', 'g-696', 'g-697', 'g-698', 'g-699', 'g-700', 'g-701', 'g-702', 'g-703', 'g-704', 'g-705', 'g-706', 'g-707', 'g-708', 'g-709', 'g-710', 'g-711', 'g-712', 'g-713', 'g-714', 'g-715', 'g-716', 'g-717', 'g-718', 'g-719', 'g-720', 'g-721', 'g-722', 'g-723', 'g-724', 'g-725', 'g-726', 'g-727', 'g-728', 'g-729', 'g-730', 'g-731', 'g-732', 'g-733', 'g-734', 'g-735', 'g-736', 'g-737', 'g-738', 'g-739', 'g-740', 'g-741', 'g-742', 'g-743', 'g-744', 'g-745', 'g-746', 'g-747', 'g-748', 'g-749', 'g-750', 'g-751', 'g-752', 'g-753', 'g-754', 'g-755', 'g-756', 'g-757', 'g-758', 'g-759', 'g-760', 'g-761', 'g-762', 'g-763', 'g-764', 'g-765', 'g-766', 'g-767', 'g-768', 'g-769', 'g-770', 'g-771', 'c-0', 'c-1', 'c-2', 'c-3', 'c-4', 'c-5', 'c-6', 'c-7', 'c-8', 'c-9', 'c-10', 'c-11', 'c-12', 'c-13', 'c-14', 'c-15', 'c-16', 'c-17', 'c-18', 'c-19', 'c-20', 'c-21', 'c-22', 'c-23', 'c-24', 'c-25', 'c-26', 'c-27', 'c-28', 'c-29', 'c-30', 'c-31', 'c-32', 'c-33', 'c-34', 'c-35', 'c-36', 'c-37', 'c-38', 'c-39', 'c-40', 'c-41', 'c-42', 'c-43', 'c-44', 'c-45', 'c-46', 'c-47', 'c-48', 'c-49', 'c-50', 'c-51', 'c-52', 'c-53', 'c-54', 'c-55', 'c-56', 'c-57', 'c-58', 'c-59', 'c-60', 'c-61', 'c-62', 'c-63', 'c-64', 'c-65', 'c-66', 'c-67', 'c-68', 'c-69', 'c-70', 'c-71', 'c-72', 'c-73', 'c-74', 'c-75', 'c-76', 'c-77', 'c-78', 'c-79', 'c-80', 'c-81', 'c-82', 'c-83', 'c-84', 'c-85', 'c-86', 'c-87', 'c-88', 'c-89', 'c-90', 'c-91', 'c-92', 'c-93', 'c-94', 'c-95', 'c-96', 'c-97', 'c-98', 'c-99']\n"
     ]
    }
   ],
   "source": [
    "features = [f for f in train_data.columns if f not in [\"sig_id\"]]\n",
    "print((features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:15.358952Z",
     "iopub.status.busy": "2020-10-25T13:15:15.358197Z",
     "iopub.status.idle": "2020-10-25T13:15:15.363967Z",
     "shell.execute_reply": "2020-10-25T13:15:15.363308Z"
    },
    "papermill": {
     "duration": 0.034863,
     "end_time": "2020-10-25T13:15:15.364059",
     "exception": false,
     "start_time": "2020-10-25T13:15:15.329196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g-0', 'g-1', 'g-2', 'g-3', 'g-4', 'g-5', 'g-6', 'g-7', 'g-8', 'g-9', 'g-10', 'g-11', 'g-12', 'g-13', 'g-14', 'g-15', 'g-16', 'g-17', 'g-18', 'g-19', 'g-20', 'g-21', 'g-22', 'g-23', 'g-24', 'g-25', 'g-26', 'g-27', 'g-28', 'g-29', 'g-30', 'g-31', 'g-32', 'g-33', 'g-34', 'g-35', 'g-36', 'g-37', 'g-38', 'g-39', 'g-40', 'g-41', 'g-42', 'g-43', 'g-44', 'g-45', 'g-46', 'g-47', 'g-48', 'g-49', 'g-50', 'g-51', 'g-52', 'g-53', 'g-54', 'g-55', 'g-56', 'g-57', 'g-58', 'g-59', 'g-60', 'g-61', 'g-62', 'g-63', 'g-64', 'g-65', 'g-66', 'g-67', 'g-68', 'g-69', 'g-70', 'g-71', 'g-72', 'g-73', 'g-74', 'g-75', 'g-76', 'g-77', 'g-78', 'g-79', 'g-80', 'g-81', 'g-82', 'g-83', 'g-84', 'g-85', 'g-86', 'g-87', 'g-88', 'g-89', 'g-90', 'g-91', 'g-92', 'g-93', 'g-94', 'g-95', 'g-96', 'g-97', 'g-98', 'g-99', 'g-100', 'g-101', 'g-102', 'g-103', 'g-104', 'g-105', 'g-106', 'g-107', 'g-108', 'g-109', 'g-110', 'g-111', 'g-112', 'g-113', 'g-114', 'g-115', 'g-116', 'g-117', 'g-118', 'g-119', 'g-120', 'g-121', 'g-122', 'g-123', 'g-124', 'g-125', 'g-126', 'g-127', 'g-128', 'g-129', 'g-130', 'g-131', 'g-132', 'g-133', 'g-134', 'g-135', 'g-136', 'g-137', 'g-138', 'g-139', 'g-140', 'g-141', 'g-142', 'g-143', 'g-144', 'g-145', 'g-146', 'g-147', 'g-148', 'g-149', 'g-150', 'g-151', 'g-152', 'g-153', 'g-154', 'g-155', 'g-156', 'g-157', 'g-158', 'g-159', 'g-160', 'g-161', 'g-162', 'g-163', 'g-164', 'g-165', 'g-166', 'g-167', 'g-168', 'g-169', 'g-170', 'g-171', 'g-172', 'g-173', 'g-174', 'g-175', 'g-176', 'g-177', 'g-178', 'g-179', 'g-180', 'g-181', 'g-182', 'g-183', 'g-184', 'g-185', 'g-186', 'g-187', 'g-188', 'g-189', 'g-190', 'g-191', 'g-192', 'g-193', 'g-194', 'g-195', 'g-196', 'g-197', 'g-198', 'g-199', 'g-200', 'g-201', 'g-202', 'g-203', 'g-204', 'g-205', 'g-206', 'g-207', 'g-208', 'g-209', 'g-210', 'g-211', 'g-212', 'g-213', 'g-214', 'g-215', 'g-216', 'g-217', 'g-218', 'g-219', 'g-220', 'g-221', 'g-222', 'g-223', 'g-224', 'g-225', 'g-226', 'g-227', 'g-228', 'g-229', 'g-230', 'g-231', 'g-232', 'g-233', 'g-234', 'g-235', 'g-236', 'g-237', 'g-238', 'g-239', 'g-240', 'g-241', 'g-242', 'g-243', 'g-244', 'g-245', 'g-246', 'g-247', 'g-248', 'g-249', 'g-250', 'g-251', 'g-252', 'g-253', 'g-254', 'g-255', 'g-256', 'g-257', 'g-258', 'g-259', 'g-260', 'g-261', 'g-262', 'g-263', 'g-264', 'g-265', 'g-266', 'g-267', 'g-268', 'g-269', 'g-270', 'g-271', 'g-272', 'g-273', 'g-274', 'g-275', 'g-276', 'g-277', 'g-278', 'g-279', 'g-280', 'g-281', 'g-282', 'g-283', 'g-284', 'g-285', 'g-286', 'g-287', 'g-288', 'g-289', 'g-290', 'g-291', 'g-292', 'g-293', 'g-294', 'g-295', 'g-296', 'g-297', 'g-298', 'g-299', 'g-300', 'g-301', 'g-302', 'g-303', 'g-304', 'g-305', 'g-306', 'g-307', 'g-308', 'g-309', 'g-310', 'g-311', 'g-312', 'g-313', 'g-314', 'g-315', 'g-316', 'g-317', 'g-318', 'g-319', 'g-320', 'g-321', 'g-322', 'g-323', 'g-324', 'g-325', 'g-326', 'g-327', 'g-328', 'g-329', 'g-330', 'g-331', 'g-332', 'g-333', 'g-334', 'g-335', 'g-336', 'g-337', 'g-338', 'g-339', 'g-340', 'g-341', 'g-342', 'g-343', 'g-344', 'g-345', 'g-346', 'g-347', 'g-348', 'g-349', 'g-350', 'g-351', 'g-352', 'g-353', 'g-354', 'g-355', 'g-356', 'g-357', 'g-358', 'g-359', 'g-360', 'g-361', 'g-362', 'g-363', 'g-364', 'g-365', 'g-366', 'g-367', 'g-368', 'g-369', 'g-370', 'g-371', 'g-372', 'g-373', 'g-374', 'g-375', 'g-376', 'g-377', 'g-378', 'g-379', 'g-380', 'g-381', 'g-382', 'g-383', 'g-384', 'g-385', 'g-386', 'g-387', 'g-388', 'g-389', 'g-390', 'g-391', 'g-392', 'g-393', 'g-394', 'g-395', 'g-396', 'g-397', 'g-398', 'g-399', 'g-400', 'g-401', 'g-402', 'g-403', 'g-404', 'g-405', 'g-406', 'g-407', 'g-408', 'g-409', 'g-410', 'g-411', 'g-412', 'g-413', 'g-414', 'g-415', 'g-416', 'g-417', 'g-418', 'g-419', 'g-420', 'g-421', 'g-422', 'g-423', 'g-424', 'g-425', 'g-426', 'g-427', 'g-428', 'g-429', 'g-430', 'g-431', 'g-432', 'g-433', 'g-434', 'g-435', 'g-436', 'g-437', 'g-438', 'g-439', 'g-440', 'g-441', 'g-442', 'g-443', 'g-444', 'g-445', 'g-446', 'g-447', 'g-448', 'g-449', 'g-450', 'g-451', 'g-452', 'g-453', 'g-454', 'g-455', 'g-456', 'g-457', 'g-458', 'g-459', 'g-460', 'g-461', 'g-462', 'g-463', 'g-464', 'g-465', 'g-466', 'g-467', 'g-468', 'g-469', 'g-470', 'g-471', 'g-472', 'g-473', 'g-474', 'g-475', 'g-476', 'g-477', 'g-478', 'g-479', 'g-480', 'g-481', 'g-482', 'g-483', 'g-484', 'g-485', 'g-486', 'g-487', 'g-488', 'g-489', 'g-490', 'g-491', 'g-492', 'g-493', 'g-494', 'g-495', 'g-496', 'g-497', 'g-498', 'g-499', 'g-500', 'g-501', 'g-502', 'g-503', 'g-504', 'g-505', 'g-506', 'g-507', 'g-508', 'g-509', 'g-510', 'g-511', 'g-512', 'g-513', 'g-514', 'g-515', 'g-516', 'g-517', 'g-518', 'g-519', 'g-520', 'g-521', 'g-522', 'g-523', 'g-524', 'g-525', 'g-526', 'g-527', 'g-528', 'g-529', 'g-530', 'g-531', 'g-532', 'g-533', 'g-534', 'g-535', 'g-536', 'g-537', 'g-538', 'g-539', 'g-540', 'g-541', 'g-542', 'g-543', 'g-544', 'g-545', 'g-546', 'g-547', 'g-548', 'g-549', 'g-550', 'g-551', 'g-552', 'g-553', 'g-554', 'g-555', 'g-556', 'g-557', 'g-558', 'g-559', 'g-560', 'g-561', 'g-562', 'g-563', 'g-564', 'g-565', 'g-566', 'g-567', 'g-568', 'g-569', 'g-570', 'g-571', 'g-572', 'g-573', 'g-574', 'g-575', 'g-576', 'g-577', 'g-578', 'g-579', 'g-580', 'g-581', 'g-582', 'g-583', 'g-584', 'g-585', 'g-586', 'g-587', 'g-588', 'g-589', 'g-590', 'g-591', 'g-592', 'g-593', 'g-594', 'g-595', 'g-596', 'g-597', 'g-598', 'g-599', 'g-600', 'g-601', 'g-602', 'g-603', 'g-604', 'g-605', 'g-606', 'g-607', 'g-608', 'g-609', 'g-610', 'g-611', 'g-612', 'g-613', 'g-614', 'g-615', 'g-616', 'g-617', 'g-618', 'g-619', 'g-620', 'g-621', 'g-622', 'g-623', 'g-624', 'g-625', 'g-626', 'g-627', 'g-628', 'g-629', 'g-630', 'g-631', 'g-632', 'g-633', 'g-634', 'g-635', 'g-636', 'g-637', 'g-638', 'g-639', 'g-640', 'g-641', 'g-642', 'g-643', 'g-644', 'g-645', 'g-646', 'g-647', 'g-648', 'g-649', 'g-650', 'g-651', 'g-652', 'g-653', 'g-654', 'g-655', 'g-656', 'g-657', 'g-658', 'g-659', 'g-660', 'g-661', 'g-662', 'g-663', 'g-664', 'g-665', 'g-666', 'g-667', 'g-668', 'g-669', 'g-670', 'g-671', 'g-672', 'g-673', 'g-674', 'g-675', 'g-676', 'g-677', 'g-678', 'g-679', 'g-680', 'g-681', 'g-682', 'g-683', 'g-684', 'g-685', 'g-686', 'g-687', 'g-688', 'g-689', 'g-690', 'g-691', 'g-692', 'g-693', 'g-694', 'g-695', 'g-696', 'g-697', 'g-698', 'g-699', 'g-700', 'g-701', 'g-702', 'g-703', 'g-704', 'g-705', 'g-706', 'g-707', 'g-708', 'g-709', 'g-710', 'g-711', 'g-712', 'g-713', 'g-714', 'g-715', 'g-716', 'g-717', 'g-718', 'g-719', 'g-720', 'g-721', 'g-722', 'g-723', 'g-724', 'g-725', 'g-726', 'g-727', 'g-728', 'g-729', 'g-730', 'g-731', 'g-732', 'g-733', 'g-734', 'g-735', 'g-736', 'g-737', 'g-738', 'g-739', 'g-740', 'g-741', 'g-742', 'g-743', 'g-744', 'g-745', 'g-746', 'g-747', 'g-748', 'g-749', 'g-750', 'g-751', 'g-752', 'g-753', 'g-754', 'g-755', 'g-756', 'g-757', 'g-758', 'g-759', 'g-760', 'g-761', 'g-762', 'g-763', 'g-764', 'g-765', 'g-766', 'g-767', 'g-768', 'g-769', 'g-770', 'g-771', 'c-0', 'c-1', 'c-2', 'c-3', 'c-4', 'c-5', 'c-6', 'c-7', 'c-8', 'c-9', 'c-10', 'c-11', 'c-12', 'c-13', 'c-14', 'c-15', 'c-16', 'c-17', 'c-18', 'c-19', 'c-20', 'c-21', 'c-22', 'c-23', 'c-24', 'c-25', 'c-26', 'c-27', 'c-28', 'c-29', 'c-30', 'c-31', 'c-32', 'c-33', 'c-34', 'c-35', 'c-36', 'c-37', 'c-38', 'c-39', 'c-40', 'c-41', 'c-42', 'c-43', 'c-44', 'c-45', 'c-46', 'c-47', 'c-48', 'c-49', 'c-50', 'c-51', 'c-52', 'c-53', 'c-54', 'c-55', 'c-56', 'c-57', 'c-58', 'c-59', 'c-60', 'c-61', 'c-62', 'c-63', 'c-64', 'c-65', 'c-66', 'c-67', 'c-68', 'c-69', 'c-70', 'c-71', 'c-72', 'c-73', 'c-74', 'c-75', 'c-76', 'c-77', 'c-78', 'c-79', 'c-80', 'c-81', 'c-82', 'c-83', 'c-84', 'c-85', 'c-86', 'c-87', 'c-88', 'c-89', 'c-90', 'c-91', 'c-92', 'c-93', 'c-94', 'c-95', 'c-96', 'c-97', 'c-98', 'c-99']\n"
     ]
    }
   ],
   "source": [
    "num_features = [f for f in train_data.columns if f not in [\"sig_id\",'cp_type','cp_time','cp_dose']]\n",
    "print((num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:15.415624Z",
     "iopub.status.busy": "2020-10-25T13:15:15.414976Z",
     "iopub.status.idle": "2020-10-25T13:15:15.421133Z",
     "shell.execute_reply": "2020-10-25T13:15:15.420671Z"
    },
    "papermill": {
     "duration": 0.033798,
     "end_time": "2020-10-25T13:15:15.421225",
     "exception": false,
     "start_time": "2020-10-25T13:15:15.387427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for feat in num_features:\\n    #tr_mean = np.mean(train_data[feat].values,axis=0)\\n    #tr_std = np.std(train_data[feat].values,axis=0)\\n    tr_min = train_data[feat].values.min()\\n    tr_max = train_data[feat].values.max()\\n    ts_min = test_data[feat].values.min()\\n    ts_max = test_data[feat].values.max()\\n    \\n    train_data.loc[:,feat] = (train_data[feat].values - tr_min) / (tr_max - tr_min)\\n    test_data.loc[:,feat] = (test_data[feat].values - ts_min) / (ts_max - ts_min)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''for feat in num_features:\n",
    "    #tr_mean = np.mean(train_data[feat].values,axis=0)\n",
    "    #tr_std = np.std(train_data[feat].values,axis=0)\n",
    "    tr_min = train_data[feat].values.min()\n",
    "    tr_max = train_data[feat].values.max()\n",
    "    ts_min = test_data[feat].values.min()\n",
    "    ts_max = test_data[feat].values.max()\n",
    "    \n",
    "    train_data.loc[:,feat] = (train_data[feat].values - tr_min) / (tr_max - tr_min)\n",
    "    test_data.loc[:,feat] = (test_data[feat].values - ts_min) / (ts_max - ts_min)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:15.483185Z",
     "iopub.status.busy": "2020-10-25T13:15:15.482566Z",
     "iopub.status.idle": "2020-10-25T13:15:21.642536Z",
     "shell.execute_reply": "2020-10-25T13:15:21.641955Z"
    },
    "papermill": {
     "duration": 6.197252,
     "end_time": "2020-10-25T13:15:21.642670",
     "exception": false,
     "start_time": "2020-10-25T13:15:15.445418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_addons as tfa\n",
    "from keras import backend as K\n",
    "from keras import callbacks\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def get_cat_features(inputs,df, cate_features):\n",
    "    #inputs = []\n",
    "    outputs = []\n",
    "    for idx,cat in enumerate(cate_features):\n",
    "        uniqu_val = int(df[cat].nunique())\n",
    "        #print(uniqu_val)\n",
    "        emb_dim = int(min(np.ceil(uniqu_val/2),50))\n",
    "        inp = inputs[idx]\n",
    "        out = layers.Embedding(input_dim=uniqu_val+1,output_dim=emb_dim)(inp)\n",
    "        out = layers.Reshape(target_shape=(emb_dim,))(out)\n",
    "        #inputs.append(inp)\n",
    "        outputs.append(out) \n",
    "    y = layers.Concatenate()(outputs)  \n",
    "    return y\n",
    "\n",
    "def get_num_features(inputs,num_features):\n",
    "    inputs0 = []\n",
    "    for idx,cat in enumerate(num_features):\n",
    "        inp = inputs[idx]\n",
    "        inputs0.append(inp)\n",
    "        \n",
    "    y = layers.Concatenate()(inputs0)    \n",
    "    return y\n",
    "\n",
    "def get_inputs(features):\n",
    "    inputs0 = []\n",
    "    for num in features:\n",
    "        inp = layers.Input(shape=(1,))\n",
    "        inputs0.append(inp)\n",
    "        \n",
    "    #y = layers.Concatenate()(inputs0)    \n",
    "    return inputs0\n",
    "\n",
    "\n",
    "\n",
    "#tf.keras.utils.plot_model(model, show_shapes = False, show_layer_names= True,\n",
    "                          #rankdir = 'TB', expand_nested = False, dpi = 96)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:21.702334Z",
     "iopub.status.busy": "2020-10-25T13:15:21.701222Z",
     "iopub.status.idle": "2020-10-25T13:15:21.706072Z",
     "shell.execute_reply": "2020-10-25T13:15:21.706581Z"
    },
    "papermill": {
     "duration": 0.036446,
     "end_time": "2020-10-25T13:15:21.706735",
     "exception": false,
     "start_time": "2020-10-25T13:15:21.670289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\\n\\n\\n\\nif __name__ == \"__main__\":\\n    df = pd.merge(train_data,train_target_scored,on=\\'sig_id\\')\\n    df[\\'kfold\\'] = -1\\n    total_features = [\\'sig_id\\']+features+num_features\\n    #print(total_features)\\n    targets = [f for f in df.columns if f not in total_features]\\n    \\n    df = df.sample(frac=1).reset_index(drop=True)\\n    y = df.loc[:,targets].values\\n\\n    kf = MultilabelStratifiedKFold(n_splits=5)\\n\\n    for fold, (train, val) in enumerate(kf.split(X=df,y=y)):\\n        df.loc[val, \\'kfold\\'] = fold\\n\\n    df.to_csv(\\'./stratified_train_kfolds.csv\\', index=False)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.merge(train_data,train_target_scored,on='sig_id')\n",
    "    df['kfold'] = -1\n",
    "    total_features = ['sig_id']+features+num_features\n",
    "    #print(total_features)\n",
    "    targets = [f for f in df.columns if f not in total_features]\n",
    "    \n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    y = df.loc[:,targets].values\n",
    "\n",
    "    kf = MultilabelStratifiedKFold(n_splits=5)\n",
    "\n",
    "    for fold, (train, val) in enumerate(kf.split(X=df,y=y)):\n",
    "        df.loc[val, 'kfold'] = fold\n",
    "\n",
    "    df.to_csv('./stratified_train_kfolds.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:21.791113Z",
     "iopub.status.busy": "2020-10-25T13:15:21.790236Z",
     "iopub.status.idle": "2020-10-25T13:15:21.794199Z",
     "shell.execute_reply": "2020-10-25T13:15:21.794762Z"
    },
    "papermill": {
     "duration": 0.061679,
     "end_time": "2020-10-25T13:15:21.794887",
     "exception": false,
     "start_time": "2020-10-25T13:15:21.733208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbest_param: \\n{\\'hidden_size\\': 1655, \\'dropout\\': 0.3818704648045326, \\'learning_rate\\': 0.0007188788763769456, \\'batch_size\\': 261}\\nhidden:512, dropout:0.45,lr:0.008,bs:64/2048\\ndef objective(trial):\\n    params = {\\n         #\"hidden_size\":trial.suggest_int(\"hidden_size\",16,2048),\\n         #\"dropout\":trial.suggest_float(\"dropout\",0.1,0.8),\\n         \"learning_rate\":trial.suggest_loguniform(\"learning_rate\",1e-6,1e-3)\\n    }\\n     \\n    tot_loss = []\\n    for fold_ in range(5):\\n        loss = train(fold_,params)\\n        tot_loss.append(loss)\\n    return np.mean(tot_loss) \\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(fold):\n",
    "    print(f\"fold: {fold}\")\n",
    "    data = pd.read_csv('/kaggle/input/moa-comp/stratified_train_kfolds.csv')\n",
    "    df_train = data[data.kfold != fold].reset_index(drop=True)\n",
    "    df_val = data[data.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    x_train = [df_train.loc[:,feat].values for feat in features]\n",
    "    y_train = df_train.drop(['sig_id']+features+['kfold'],axis=1).values\n",
    "\n",
    "    x_val = [df_val.loc[:,feat].values for feat in features]\n",
    "    y_val = df_val.drop(['sig_id']+features+['kfold'],axis=1).values\n",
    "\n",
    "    #print(len(x_train))\n",
    "    #print(y_train.shape)\n",
    "    \n",
    "    inp = get_inputs(features)\n",
    "    y_cat = get_cat_features(inp,train_data,cat_features)\n",
    "    y_num = get_num_features(inp,num_features)\n",
    "\n",
    "    y = layers.Concatenate()([y_cat,y_num])\n",
    "    y = tfa.layers.WeightNormalization(layers.Dense(units=1655,activation='elu'\n",
    "                                                    ,kernel_initializer=tf.keras.initializers.GlorotNormal()))(y)\n",
    "\n",
    "    y = layers.Dropout(0.38)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    \n",
    "    #y = tfa.layers.WeightNormalization(layers.Dense(units=1655,activation='elu'))(y)\n",
    "    #y = layers.Dropout(0.38)(y)\n",
    "    #y = layers.BatchNormalization()(y)\n",
    "    \n",
    "    y = tfa.layers.WeightNormalization(layers.Dense(1655,activation='elu',\n",
    "                                                    kernel_initializer=tf.keras.initializers.GlorotNormal()))(y)\n",
    "\n",
    "    y = layers.Dropout(0.38)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dense(206,activation='sigmoid')(y)\n",
    "\n",
    "    model = Model(inputs=inp,outputs=y)\n",
    "\n",
    "    #model.summary()\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=5,\n",
    "            verbose=1, mode=\"min\", baseline=None,   restore_best_weights=True)\n",
    "    rlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                      patience=5, min_lr=1e-6, mode='max', verbose=1)\n",
    "     \n",
    "    #optimizer=tfa.optimizers.Lookahead(tf.keras.optimizers.Adam(lr=0.00072)\n",
    "    #learning_rate_fn = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=0.0005)\n",
    "    sgd=tf.keras.optimizers.Adam(lr=0.00072)                                   \n",
    "    stocastic_avg_sgd = tfa.optimizers.SWA(sgd)\n",
    "    #avg_callback = tfa.callbacks.AverageModelCheckpoint(filepath='/kaggle/working', save_weights_only=True,\n",
    "     #                                               update_weights=True)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "    optimizer=stocastic_avg_sgd)\n",
    "\n",
    "    model.fit(x_train,y_train,batch_size=261,epochs=21,validation_data=(x_val,y_val))#,callbacks=[avg_callback])\n",
    "    model.save(f\"/kaggle/working/model_{fold}.h5\")\n",
    "    score = model.evaluate(x_val,y_val)\n",
    "    print(score)\n",
    "    return score,model\n",
    "\n",
    "'''\n",
    "best_param: \n",
    "{'hidden_size': 1655, 'dropout': 0.3818704648045326, 'learning_rate': 0.0007188788763769456, 'batch_size': 261}\n",
    "hidden:512, dropout:0.45,lr:0.008,bs:64/2048\n",
    "def objective(trial):\n",
    "    params = {\n",
    "         #\"hidden_size\":trial.suggest_int(\"hidden_size\",16,2048),\n",
    "         #\"dropout\":trial.suggest_float(\"dropout\",0.1,0.8),\n",
    "         \"learning_rate\":trial.suggest_loguniform(\"learning_rate\",1e-6,1e-3)\n",
    "    }\n",
    "     \n",
    "    tot_loss = []\n",
    "    for fold_ in range(5):\n",
    "        loss = train(fold_,params)\n",
    "        tot_loss.append(loss)\n",
    "    return np.mean(tot_loss) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:21.854502Z",
     "iopub.status.busy": "2020-10-25T13:15:21.853379Z",
     "iopub.status.idle": "2020-10-25T13:15:21.858273Z",
     "shell.execute_reply": "2020-10-25T13:15:21.857767Z"
    },
    "papermill": {
     "duration": 0.035666,
     "end_time": "2020-10-25T13:15:21.858374",
     "exception": false,
     "start_time": "2020-10-25T13:15:21.822708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom functools import partial\\nimport optuna\\n\\nstudy = optuna.create_study(direction=\\'minimize\\')\\nstudy.optimize(objective,n_trials=2)\\n   \\nprint(\"best_trial: \")\\ntrial_ = study.best_trial\\nprint(\"value: {}\".format(trial_.value))\\n\\n\\nprint(\"best_param: \")\\nbest_params = trial_.params\\nprint(best_params)\\n\\nscores = 0\\nfor j in range(5):\\n    score = train(fold=j,params=best_params)\\n    scores += score\\n\\nprint(scores/5)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from functools import partial\n",
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective,n_trials=2)\n",
    "   \n",
    "print(\"best_trial: \")\n",
    "trial_ = study.best_trial\n",
    "print(\"value: {}\".format(trial_.value))\n",
    "\n",
    "\n",
    "print(\"best_param: \")\n",
    "best_params = trial_.params\n",
    "print(best_params)\n",
    "\n",
    "scores = 0\n",
    "for j in range(5):\n",
    "    score = train(fold=j,params=best_params)\n",
    "    scores += score\n",
    "\n",
    "print(scores/5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:15:21.918695Z",
     "iopub.status.busy": "2020-10-25T13:15:21.918046Z",
     "iopub.status.idle": "2020-10-25T13:29:20.706689Z",
     "shell.execute_reply": "2020-10-25T13:29:20.705726Z"
    },
    "papermill": {
     "duration": 838.821949,
     "end_time": "2020-10-25T13:29:20.706838",
     "exception": false,
     "start_time": "2020-10-25T13:15:21.884889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "Epoch 1/21\n",
      "73/73 [==============================] - 11s 148ms/step - loss: 0.5430 - val_loss: 0.1199\n",
      "Epoch 2/21\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.0562 - val_loss: 0.0284\n",
      "Epoch 3/21\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0242 - val_loss: 0.0200\n",
      "Epoch 4/21\n",
      "73/73 [==============================] - 5s 75ms/step - loss: 0.0206 - val_loss: 0.0188\n",
      "Epoch 5/21\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0189 - val_loss: 0.0183\n",
      "Epoch 6/21\n",
      "73/73 [==============================] - 5s 75ms/step - loss: 0.0180 - val_loss: 0.0173\n",
      "Epoch 7/21\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.0174 - val_loss: 0.0174\n",
      "Epoch 8/21\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0171 - val_loss: 0.0167\n",
      "Epoch 9/21\n",
      "73/73 [==============================] - 5s 75ms/step - loss: 0.0165 - val_loss: 0.0166\n",
      "Epoch 10/21\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.0160 - val_loss: 0.0163\n",
      "Epoch 11/21\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.0155 - val_loss: 0.0161\n",
      "Epoch 12/21\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.0147 - val_loss: 0.0160\n",
      "Epoch 13/21\n",
      "73/73 [==============================] - 6s 76ms/step - loss: 0.0143 - val_loss: 0.0160\n",
      "Epoch 14/21\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.0143 - val_loss: 0.0160\n",
      "Epoch 15/21\n",
      "73/73 [==============================] - 6s 77ms/step - loss: 0.0134 - val_loss: 0.0161\n",
      "Epoch 16/21\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0132 - val_loss: 0.0160\n",
      "Epoch 17/21\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.0123 - val_loss: 0.0162\n",
      "Epoch 18/21\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.0119 - val_loss: 0.0161\n",
      "Epoch 19/21\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.0113 - val_loss: 0.0178\n",
      "Epoch 20/21\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.0114 - val_loss: 0.0166\n",
      "Epoch 21/21\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.0106 - val_loss: 0.0163\n",
      "149/149 [==============================] - 7s 49ms/step - loss: 0.0163\n",
      "0.016347484663128853\n",
      "fold: 1\n",
      "Epoch 1/21\n",
      "73/73 [==============================] - 11s 154ms/step - loss: 0.5413 - val_loss: 0.1159\n",
      "Epoch 2/21\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.0541 - val_loss: 0.0257\n",
      "Epoch 3/21\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.0243 - val_loss: 0.0194\n",
      "Epoch 4/21\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.0204 - val_loss: 0.0183\n",
      "Epoch 5/21\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.0188 - val_loss: 0.0178\n",
      "Epoch 6/21\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 7/21\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0173 - val_loss: 0.0170\n",
      "Epoch 8/21\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.0166 - val_loss: 0.0166\n",
      "Epoch 9/21\n",
      "73/73 [==============================] - 5s 75ms/step - loss: 0.0161 - val_loss: 0.0161\n",
      "Epoch 10/21\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.0157 - val_loss: 0.0161\n",
      "Epoch 11/21\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.0154 - val_loss: 0.0162\n",
      "Epoch 12/21\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 13/21\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.0144 - val_loss: 0.0156\n",
      "Epoch 14/21\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.0139 - val_loss: 0.0157\n",
      "Epoch 15/21\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0134 - val_loss: 0.0159\n",
      "Epoch 16/21\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.0130 - val_loss: 0.0157\n",
      "Epoch 17/21\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 18/21\n",
      "73/73 [==============================] - 5s 75ms/step - loss: 0.0117 - val_loss: 0.0157\n",
      "Epoch 19/21\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0111 - val_loss: 0.0160\n",
      "Epoch 20/21\n",
      "73/73 [==============================] - 6s 76ms/step - loss: 0.0108 - val_loss: 0.0159\n",
      "Epoch 21/21\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.0103 - val_loss: 0.0164\n",
      "149/149 [==============================] - 7s 48ms/step - loss: 0.0164\n",
      "0.016368797048926353\n",
      "fold: 2\n",
      "Epoch 1/21\n",
      "73/73 [==============================] - 12s 160ms/step - loss: 0.5430 - val_loss: 0.1225\n",
      "Epoch 2/21\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.0549 - val_loss: 0.0256\n",
      "Epoch 3/21\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.0241 - val_loss: 0.0209\n",
      "Epoch 4/21\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0205 - val_loss: 0.0183\n",
      "Epoch 5/21\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.0188 - val_loss: 0.0180\n",
      "Epoch 6/21\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.0178 - val_loss: 0.0173\n",
      "Epoch 7/21\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.0170 - val_loss: 0.0167\n",
      "Epoch 8/21\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.0163 - val_loss: 0.0164\n",
      "Epoch 9/21\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.0160 - val_loss: 0.0165\n",
      "Epoch 10/21\n",
      "73/73 [==============================] - 8s 106ms/step - loss: 0.0155 - val_loss: 0.0161\n",
      "Epoch 11/21\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.0151 - val_loss: 0.0163\n",
      "Epoch 12/21\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0153 - val_loss: 0.0160\n",
      "Epoch 13/21\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.0151 - val_loss: 0.0160\n",
      "Epoch 14/21\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.0141 - val_loss: 0.0162\n",
      "Epoch 15/21\n",
      "73/73 [==============================] - 9s 118ms/step - loss: 0.0136 - val_loss: 0.0166\n",
      "Epoch 16/21\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.0131 - val_loss: 0.0159\n",
      "Epoch 17/21\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0123 - val_loss: 0.0162\n",
      "Epoch 18/21\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.0120 - val_loss: 0.0160\n",
      "Epoch 19/21\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.0114 - val_loss: 0.0161\n",
      "Epoch 20/21\n",
      "73/73 [==============================] - 8s 108ms/step - loss: 0.0113 - val_loss: 0.0164\n",
      "Epoch 21/21\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.0108 - val_loss: 0.0165\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 0.0165\n",
      "0.01647026091814041\n",
      "fold: 3\n",
      "Epoch 1/21\n",
      "73/73 [==============================] - 10s 142ms/step - loss: 0.5431 - val_loss: 0.1182\n",
      "Epoch 2/21\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0553 - val_loss: 0.0261\n",
      "Epoch 3/21\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0243 - val_loss: 0.0201\n",
      "Epoch 4/21\n",
      "73/73 [==============================] - 8s 103ms/step - loss: 0.0205 - val_loss: 0.0188\n",
      "Epoch 5/21\n",
      "73/73 [==============================] - 6s 76ms/step - loss: 0.0189 - val_loss: 0.0178\n",
      "Epoch 6/21\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 7/21\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0172 - val_loss: 0.0169\n",
      "Epoch 8/21\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 9/21\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 10/21\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.0157 - val_loss: 0.0163\n",
      "Epoch 11/21\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.0156 - val_loss: 0.0166\n",
      "Epoch 12/21\n",
      "73/73 [==============================] - 6s 76ms/step - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 13/21\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.0146 - val_loss: 0.0162\n",
      "Epoch 14/21\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 15/21\n",
      "73/73 [==============================] - 7s 99ms/step - loss: 0.0135 - val_loss: 0.0162\n",
      "Epoch 16/21\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.0131 - val_loss: 0.0162\n",
      "Epoch 17/21\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 18/21\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.0119 - val_loss: 0.0161\n",
      "Epoch 19/21\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.0113 - val_loss: 0.0163\n",
      "Epoch 20/21\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0109 - val_loss: 0.0161\n",
      "Epoch 21/21\n",
      "73/73 [==============================] - 7s 98ms/step - loss: 0.0105 - val_loss: 0.0163\n",
      "149/149 [==============================] - 6s 41ms/step - loss: 0.0163\n",
      "0.016345864161849022\n",
      "fold: 4\n",
      "Epoch 1/21\n",
      "73/73 [==============================] - 12s 168ms/step - loss: 0.5416 - val_loss: 0.1112\n",
      "Epoch 2/21\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.0544 - val_loss: 0.0248\n",
      "Epoch 3/21\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.0238 - val_loss: 0.0203\n",
      "Epoch 4/21\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.0202 - val_loss: 0.0185\n",
      "Epoch 5/21\n",
      "73/73 [==============================] - 6s 75ms/step - loss: 0.0188 - val_loss: 0.0177\n",
      "Epoch 6/21\n",
      "73/73 [==============================] - 8s 109ms/step - loss: 0.0179 - val_loss: 0.0174\n",
      "Epoch 7/21\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.0171 - val_loss: 0.0169\n",
      "Epoch 8/21\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.0170 - val_loss: 0.0167\n",
      "Epoch 9/21\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.0165 - val_loss: 0.0165\n",
      "Epoch 10/21\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.0157 - val_loss: 0.0162\n",
      "Epoch 11/21\n",
      "73/73 [==============================] - 8s 114ms/step - loss: 0.0152 - val_loss: 0.0160\n",
      "Epoch 12/21\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.0147 - val_loss: 0.0160\n",
      "Epoch 13/21\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.0141 - val_loss: 0.0158\n",
      "Epoch 14/21\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.0139 - val_loss: 0.0163\n",
      "Epoch 15/21\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0133 - val_loss: 0.0157\n",
      "Epoch 16/21\n",
      "73/73 [==============================] - 8s 106ms/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 17/21\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 18/21\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.0119 - val_loss: 0.0159\n",
      "Epoch 19/21\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.0113 - val_loss: 0.0160\n",
      "Epoch 20/21\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.0109 - val_loss: 0.0173\n",
      "Epoch 21/21\n",
      "73/73 [==============================] - 8s 105ms/step - loss: 0.0108 - val_loss: 0.0167\n",
      "149/149 [==============================] - 7s 48ms/step - loss: 0.0167\n",
      "0.016652686521410942\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5):\n",
    "    _,model = train(fold=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:29:26.430994Z",
     "iopub.status.busy": "2020-10-25T13:29:26.430084Z",
     "iopub.status.idle": "2020-10-25T13:30:32.799085Z",
     "shell.execute_reply": "2020-10-25T13:30:32.798101Z"
    },
    "papermill": {
     "duration": 69.275531,
     "end_time": "2020-10-25T13:30:32.799224",
     "exception": false,
     "start_time": "2020-10-25T13:29:23.523693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pred_fct(model,test_data):\n",
    "    x_test = [test_data.loc[:,feat].values for feat in features]\n",
    "    preds = model.predict(x_test)\n",
    "    #print(preds.shape)\n",
    "    return preds\n",
    "\n",
    "model_0 = tf.keras.models.load_model(\"/kaggle/working/model_0.h5\")\n",
    "model_1 = tf.keras.models.load_model(\"/kaggle/working/model_1.h5\")\n",
    "model_2 = tf.keras.models.load_model(\"/kaggle/working/model_2.h5\")\n",
    "model_3 = tf.keras.models.load_model(\"/kaggle/working/model_3.h5\")\n",
    "model_4 = tf.keras.models.load_model(\"/kaggle/working/model_4.h5\")\n",
    "\n",
    "pred0 = pred_fct(model_0,test_data)\n",
    "pred1 = pred_fct(model_1,test_data)\n",
    "pred2 = pred_fct(model_2,test_data)\n",
    "pred3 = pred_fct(model_3,test_data)\n",
    "pred4 = pred_fct(model_4,test_data)\n",
    "\n",
    "avg_pred = (pred0 + pred1 + pred2 + pred3 + pred4)/5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T13:30:38.328169Z",
     "iopub.status.busy": "2020-10-25T13:30:38.326558Z",
     "iopub.status.idle": "2020-10-25T13:30:40.981715Z",
     "shell.execute_reply": "2020-10-25T13:30:40.981086Z"
    },
    "papermill": {
     "duration": 5.462802,
     "end_time": "2020-10-25T13:30:40.981846",
     "exception": false,
     "start_time": "2020-10-25T13:30:35.519044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.001738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>0.007335</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.009125</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.008675</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.007689</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.001460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_0004d9e33                     0.000446                0.002279   \n",
       "1  id_001897cda                     0.000058                0.000732   \n",
       "2  id_002429b5b                     0.000139                0.000053   \n",
       "3  id_00276f245                     0.000121                0.000402   \n",
       "4  id_0027f1083                     0.002179                0.002569   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0        0.000986                        0.008915   \n",
       "1        0.000746                        0.000476   \n",
       "2        0.000637                        0.000171   \n",
       "3        0.000436                        0.001620   \n",
       "4        0.002600                        0.009125   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                           0.005874                        0.002047   \n",
       "1                           0.001045                        0.001196   \n",
       "2                           0.010388                        0.000092   \n",
       "3                           0.000786                        0.003540   \n",
       "4                           0.017986                        0.000918   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                    0.000597                       0.003760   \n",
       "1                    0.001756                       0.003071   \n",
       "2                    0.000446                       0.000273   \n",
       "3                    0.000356                       0.000774   \n",
       "4                    0.008675                       0.001109   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                    0.000152  ...                               0.000626   \n",
       "1                    0.002922  ...                               0.000387   \n",
       "2                    0.000086  ...                               0.000199   \n",
       "3                    0.000155  ...                               0.000154   \n",
       "4                    0.000772  ...                               0.001074   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      0.002785         0.002719           0.000404   \n",
       "1      0.000912         0.001954           0.000157   \n",
       "2      0.000122         0.000256           0.000630   \n",
       "3      0.000415         0.001609           0.014392   \n",
       "4      0.000589         0.007689           0.003800   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                   0.000220                               0.000531   \n",
       "1                   0.004110                               0.000238   \n",
       "2                   0.001898                               0.000057   \n",
       "3                   0.007335                               0.000247   \n",
       "4                   0.000548                               0.001046   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0         0.000415   0.001584                    0.004504       0.000868  \n",
       "1         0.000522   0.000284                    0.000933       0.001738  \n",
       "2         0.003378   0.001118                    0.000121       0.000672  \n",
       "3         0.001418   0.000719                    0.000260       0.000784  \n",
       "4         0.003442   0.001781                    0.000231       0.001460  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_sub = submission\n",
    "G_labels = [f for f in G_sub.columns if f not in [\"sig_id\"]]\n",
    "sub = pd.DataFrame()\n",
    "sub[\"sig_id\"] = G_sub[\"sig_id\"]\n",
    "sub[G_labels] = avg_pred\n",
    "sub.to_csv('./submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.731937,
     "end_time": "2020-10-25T13:30:46.731200",
     "exception": false,
     "start_time": "2020-10-25T13:30:43.999263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 950.917849,
   "end_time": "2020-10-25T13:30:51.253107",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-25T13:15:00.335258",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
